{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d12679ba-ba85-48db-8ff0-d04d2c0b51ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pnet/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pnet import pnet_loader, Pnet\n",
    "from util import util, sankey_diag\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import SVC\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc1d8692-0c15-4e91-8b54-a50ea24005b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prostate_mutations = pd.read_csv('/mnt/disks/pancan/pnet_database/prostate/processed/P1000_final_analysis_set_cross_important_only.csv')\n",
    "prostate_mutations.set_index('Tumor_Sample_Barcode', inplace=True)\n",
    "\n",
    "prostate_cnv = pd.read_csv('/mnt/disks/pancan/pnet_database/prostate/processed/P1000_data_CNA_paper.csv')\n",
    "prostate_cnv.rename(columns={\"Unnamed: 0\": \"Tumor_Sample_Barcode\"}, inplace=True)\n",
    "prostate_cnv.set_index('Tumor_Sample_Barcode', inplace=True)\n",
    "\n",
    "prostate_response = pd.read_csv('/mnt/disks/pancan/pnet_database/prostate/processed/response_paper.csv')\n",
    "prostate_response.rename(columns={'id': \"Tumor_Sample_Barcode\"}, inplace=True)\n",
    "prostate_response.set_index('Tumor_Sample_Barcode', inplace=True)\n",
    "\n",
    "prostate_genes = pd.read_csv('/mnt/disks/pancan/pnet_database/genes/tcga_prostate_expressed_genes_and_cancer_genes.csv')\n",
    "prostate_genes = list(set(prostate_genes['genes']).intersection(set(prostate_mutations.columns)).intersection(set(prostate_cnv.columns)))\n",
    "\n",
    "prostate_cnv = prostate_cnv[prostate_genes].copy()\n",
    "prostate_mutations = prostate_mutations[prostate_genes].copy()\n",
    "\n",
    "prostate_mutations = prostate_mutations[list(set(prostate_mutations.columns).intersection(prostate_genes))].copy()\n",
    "prostate_cnv = prostate_cnv[list(set(prostate_cnv.columns).intersection(prostate_genes))].copy()\n",
    "\n",
    "# Regenerate input as specified in prostate_paper\n",
    "prostate_mutations = (prostate_mutations > 0).astype(int)\n",
    "prostate_amp = (prostate_cnv > 1).astype(int)\n",
    "prostate_del = (prostate_cnv < -1).astype(int)\n",
    "\n",
    "genetic_data = {'mut': prostate_mutations, 'amp': prostate_amp, 'del': prostate_del}\n",
    "\n",
    "canc_genes = list(pd.read_csv('../../pnet_database/genes/cancer_genes.txt').values.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcdb59a5-e014-41c4-a8bd-f9ed417b0077",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay_values = [1e-3]\n",
    "input_dropout_values = [0.8]\n",
    "pathway_dropout_values = [0.3, 0.4, 0.5]\n",
    "learning_rate_values = [1e-2, 5e-3, 1e-3, 5e-4, 1e-4, 5e-5]\n",
    "batch_size_values = [32, 64, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c23b631-cbc4-4b08-ad83-55ee50bacbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task defined: BC \n",
      " if this is not the intended task please specify task\n",
      "Given 3 Input modalities\n",
      "Found 1011 overlapping indicies\n",
      "Initializing Train Dataset\n",
      "Found 443 overlapping genes\n",
      "generated input DataFrame of size (910, 1329)\n",
      "Initializing Test Dataset\n",
      "Found 443 overlapping genes\n",
      "generated input DataFrame of size (101, 1329)\n",
      "Found 443 overlapping genes\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "We are sending to cuda\n",
      "We are sending to cuda\n",
      "We are sending to cuda\n",
      "We are sending to cuda\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "We are sending to cuda\n",
      "We are sending to cuda\n",
      "We are sending to cuda\n",
      "We are sending to cuda\n",
      "We are sending to cuda\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n",
      "We are sending to cuda\n",
      "We are sending to cuda\n",
      "We are sending to cuda\n",
      "We are sending to cuda\n",
      "We are sending to cuda\n",
      "Hit early stopping criteria\n"
     ]
    }
   ],
   "source": [
    "class_weights = util.get_class_weights(torch.tensor(prostate_response.values).view(-1))\n",
    "task = util.get_task(prostate_response)\n",
    "target = util.format_target(prostate_response, task)\n",
    "\n",
    "train_inds = list(pd.read_csv('../data/splits/train_set_{}.csv'.format(2))['indicies'])\n",
    "test_inds = list(pd.read_csv('../data/splits/test_set_{}.csv'.format(2))['indicies'])\n",
    "train_dataset, test_dataset = pnet_loader.generate_train_test(genetic_data, target=target, train_inds=train_inds,\n",
    "                                                              test_inds=test_inds, gene_set=canc_genes, seed=123)\n",
    "\n",
    "\n",
    "x_test = test_dataset.x\n",
    "additional_test = test_dataset.additional\n",
    "y_test = test_dataset.y\n",
    "\n",
    "reactome_network = ReactomeNetwork.ReactomeNetwork(train_dataset.get_genes())\n",
    "loss_fn=nn.BCEWithLogitsLoss(reduce=None)\n",
    "\n",
    "for weight_decay in weight_decay_values:\n",
    "    for inp_drop in input_dropout_values:\n",
    "        for dropout in pathway_dropout_values:\n",
    "            for lr in learning_rate_values:\n",
    "                for batch_size in batch_size_values:\n",
    "                    save_path = '../results/hyperparam_search/wd{}_id{}_do{}_lr{}_bs{}'.format(weight_decay, inp_drop,\n",
    "                                                                                                dropout, lr, batch_size)\n",
    "                    if not os.path.exists(save_path):\n",
    "                        os.makedirs(save_path)\n",
    "                    model = Pnet.PNET_NN(reactome_network=reactome_network, task=task, nbr_gene_inputs=len(genetic_data),\n",
    "                                    dropout=dropout, additional_dims=train_dataset.additional_data.shape[1], lr=lr, \n",
    "                                    weight_decay=weight_decay, output_dim=target.shape[1], random_network=False,\n",
    "                                    fcnn=False, loss_fn=loss_fn, loss_weight=class_weights, gene_dropout=dropout,\n",
    "                                         input_dropout=inp_drop)\n",
    "                    \n",
    "                    train_loader, test_loader = pnet_loader.to_dataloader(train_dataset, test_dataset, batch_size)\n",
    "                    model, train_scores, test_scores = Pnet.train(model, train_loader, test_loader, save_path+'/model', lr,\n",
    "                                                             weight_decay, epochs=400, verbose=False, \n",
    "                                                             early_stopping=True)\n",
    "                    \n",
    "                    df = pd.DataFrame(index=['train_loss', 'test_loss'], data=[train_scores, test_scores]).transpose()\n",
    "\n",
    "                    model.to('cpu')\n",
    "                    pred, preds = model(x_test, additional_test)\n",
    "                    y_pred_proba = model.predict_proba(x_test, additional_test).detach()\n",
    "                    fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "                    test_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "                    df['auc'] = test_auc\n",
    "                    \n",
    "                    df.to_csv(save_path+'/loss.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d379b1d-a2ce-4665-bd1d-24705c1ab18b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecd0c08-0cc3-4d3a-abc8-a05aa6c90ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b20b41-a764-40fe-8829-2326b84cba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PNET_NN(reactome_network=reactome_network, task=task, nbr_gene_inputs=len(genetic_data), dropout=dropout,\n",
    "                additional_dims=train_dataset.additional_data.shape[1], lr=lr, weight_decay=weight_decay,\n",
    "                output_dim=target.shape[1], random_network=random_network, fcnn=fcnn, loss_fn=loss_fn, loss_weight=loss_weight\n",
    "                )\n",
    "train_loader, test_loader = pnet_loader.to_dataloader(train_dataset, test_dataset, batch_size)\n",
    "model, train_scores, test_scores = train(model, train_loader, test_loader, save_path, lr, weight_decay, epochs, verbose,\n",
    "                                         early_stopping)\n",
    "\n",
    "util.draw_loss(train_scores, test_scores)\n",
    "\n",
    "x_train = train_dataset.x\n",
    "additional_train = train_dataset.additional\n",
    "y_train = train_dataset.y\n",
    "x_test = test_dataset.x\n",
    "additional_test = test_dataset.additional\n",
    "y_test = test_dataset.y\n",
    "\n",
    "model.to('cpu')\n",
    "pred, preds = model(x_test, additional_test)\n",
    "y_pred_proba = model.predict_proba(x_test, additional_test).detach()\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "test_auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "#create ROC curve\n",
    "plt.plot(fpr,tpr, color=\"darkorange\", label=\"ROC curve (area = %0.2f)\" % test_auc)\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", linestyle=\"--\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f120a6-e74d-445c-af1c-33cb82259976",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run(genetic_data, target, save_path='../results/model', gene_set=None, additional_data=None, test_split=0.2, seed=None, dropout=0.3,\n",
    "        lr=1e-3, weight_decay=1, batch_size=64, epochs=300, verbose=False, early_stopping=True, train_inds=None,\n",
    "        test_inds=None, random_network=False, fcnn=False, task=None, loss_fn=None, loss_weight=None):\n",
    "\n",
    "    model = PNET_NN(reactome_network=reactome_network, task=task, nbr_gene_inputs=len(genetic_data), dropout=dropout,\n",
    "                    additional_dims=train_dataset.additional_data.shape[1], lr=lr, weight_decay=weight_decay,\n",
    "                    output_dim=target.shape[1], random_network=random_network, fcnn=fcnn, loss_fn=loss_fn, loss_weight=loss_weight\n",
    "                    )\n",
    "    train_loader, test_loader = pnet_loader.to_dataloader(train_dataset, test_dataset, batch_size)\n",
    "    model, train_scores, test_scores = train(model, train_loader, test_loader, save_path, lr, weight_decay, epochs, verbose,\n",
    "                                             early_stopping)\n",
    "    return model, train_scores, test_scores, train_dataset, test_dataset"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pnet-py",
   "name": "pytorch-gpu.1-10.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-10:m90"
  },
  "kernelspec": {
   "display_name": "Python [conda env:pnet]",
   "language": "python",
   "name": "conda-env-pnet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
